{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84f0462-6bf9-4e93-9534-7d8534ef41dc",
   "metadata": {},
   "source": [
    "## 1. Installs and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701d7dfc-bd7d-4749-b184-fcdd17dd700b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce RTX 5070 Ti Laptop GPU')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for pytorch install and CUDA availability:\n",
    "import torch\n",
    "torch.cuda.is_available(), torch.cuda.get_device_name(0) if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408d2330-c831-44fc-ab34-1b9d14170156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import random\n",
    "\n",
    "# 3rd-party libs & hugging face ecosystem \n",
    "import numpy as np\n",
    "import evaluate\n",
    "import accelerate\n",
    "import matplotlib\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42938d0c-d33e-4fa6-8eef-28f5ccb21ca9",
   "metadata": {},
   "source": [
    "## 2. Data Preparation: load, tokenize, splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e911b2-9f84-4789-b5a8-a53ab9c1c0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# load dataset (note splits)\n",
    "ds = load_dataset(\"dair-ai/emotion\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c95e9a-8e6d-49e9-93fe-07df8f8048c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model tokenizer\n",
    "MODEL_NAME = \"distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b8dad8-07aa-4085-b666-059d801cf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing function\n",
    "def tokenize_batch(batch):\n",
    "    tok = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "    # DistilRoBERTa doesn't use token_type_ids:\n",
    "    tok.pop(\"token_type_ids\", None)\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a106a7ee-5127-4487-86c2-95f00dc0db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tokenization\n",
    "ds = ds.map(tokenize_batch, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa75dfe-828a-47d0-a2f1-9dba83e561f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep columns needed for PyTorch and correct format for PyTorch\n",
    "cols_to_keep = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "ds = ds.remove_columns([c for c in ds.column_names[\"train\"] if c not in cols_to_keep])\n",
    "ds.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43502400-d9eb-4fe0-b3e9-9fe800bed292",
   "metadata": {},
   "source": [
    "## 3. Load base model & classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27faf3a8-7aea-43ed-a668-7ada2f77aa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=16000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS = len(set(ds[\"train\"][\"label\"]))\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "# print(set(ds[\"train\"][\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe0853-3729-4e3b-a90e-8648b592f140",
   "metadata": {},
   "source": [
    "## 4. Apply LoRA using PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43bd820-dbb6-4576-9d71-53cb5e955bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,042,048 || all params: 107,464,448 || trainable%: 12.1362\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\", # sequence classification\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters() # sanity - should only show LoRA params trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b778627-427d-4ae3-a4a8-92a91e102446",
   "metadata": {},
   "source": [
    "## 5. Training: Trainer + TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeea8e2f-5fbe-43cc-9094-a73f31010453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments Instantiated Successfully!\n"
     ]
    }
   ],
   "source": [
    "# metric setup\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=p.label_ids)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=p.label_ids, average=\"macro\")[\"f1\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=p.label_ids, average=\"macro\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=p.label_ids, average=\"macro\")[\"recall\"],\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./peft-emotion\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    per_device_train_batch_size=16, # adjust to fit GPU memory, use smaller if needed\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "print(\"TrainingArguments Instantiated Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488a244e-33ae-4dad-810f-f2cc11798b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 04:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.332546</td>\n",
       "      <td>0.883500</td>\n",
       "      <td>0.853027</td>\n",
       "      <td>0.848675</td>\n",
       "      <td>0.864902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.911500</td>\n",
       "      <td>0.882219</td>\n",
       "      <td>0.889927</td>\n",
       "      <td>0.876634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.279300</td>\n",
       "      <td>0.220894</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.891699</td>\n",
       "      <td>0.887327</td>\n",
       "      <td>0.897005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.5187485879262288, metrics={'train_runtime': 241.0572, 'train_samples_per_second': 199.123, 'train_steps_per_second': 12.445, 'total_flos': 2523908800512000.0, 'train_loss': 0.5187485879262288, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c08c62-7b96-4ca0-a35a-bcd292b7c31a",
   "metadata": {},
   "source": [
    "## 6. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62a44b47-c140-4176-b018-4d5de53ffacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9531    0.9449    0.9490       581\n",
      "           1     0.9371    0.9223    0.9297       695\n",
      "           2     0.7759    0.8491    0.8108       159\n",
      "           3     0.8986    0.9018    0.9002       275\n",
      "           4     0.8761    0.8839    0.8800       224\n",
      "           5     0.7344    0.7121    0.7231        66\n",
      "\n",
      "    accuracy                         0.9090      2000\n",
      "   macro avg     0.8625    0.8690    0.8655      2000\n",
      "weighted avg     0.9101    0.9090    0.9094      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = trainer.predict(ds[\"test\"])\n",
    "preds = np.argmax(results.predictions, axis=1)\n",
    "labels = results.label_ids\n",
    "\n",
    "print(classification_report(labels, preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9887eac5-9d45-48c8-9c45-d6d4891dd663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metrics: {'accuracy': 0.909, 'f1': 0.8654557409224403, 'precision': 0.8625255818695735, 'recall': 0.8690248791245195}\n"
     ]
    }
   ],
   "source": [
    "# print metric dict:\n",
    "print(\"Eval metrics:\", compute_metrics(results)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77425688-6469-4d5d-98ae-0a495a273cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chatgpt5 made this for me when I said it seemed weird I didn't \"interact\" with the emotions from the Twitter dataset:\n",
    "example = \"Iâ€™m so proud of myself today!\"\n",
    "inputs = tokenizer(example, return_tensors=\"pt\").to(model.device)\n",
    "pred = model(**inputs).logits.argmax(dim=-1).item()\n",
    "ds[\"train\"].features[\"label\"].int2str(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f56c4ef5-f9d8-40b1-9647-e870010d6f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example2 = \"Square chair eats my round table.\"\n",
    "inputs = tokenizer(example2, return_tensors=\"pt\").to(model.device)\n",
    "pred = model(**inputs).logits.argmax(dim=-1).item()\n",
    "ds[\"train\"].features[\"label\"].int2str(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2383b749-1cc8-43cc-85a3-f271f1af0504",
   "metadata": {},
   "source": [
    "## 7. Baseline Comparison (majority class accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2b190fd-f215-4061-9ead-67ce278448c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I tried to iterate over everything which I am told is 0(n^2)\n",
    "# this should be 0(n)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# count labels\n",
    "label_counts = Counter(ds[\"train\"][\"label\"])\n",
    "\n",
    "# majority class\n",
    "majority_class = label_counts.most_common(1)[0][0]\n",
    "majority_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57be9ef2-93ec-48ae-815d-b62ca95ae174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2905"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of always guessing majority class\n",
    "test_labels = ds[\"test\"][\"label\"]\n",
    "majority_baseline_acc = sum([1 for x in test_labels if x == majority_class]) / len(test_labels)\n",
    "majority_baseline_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "011dc494-6d34-4c71-92e5-f5d478fed2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"lora-distilroberta-emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f71004-4ea7-4e5b-9a84-86987cc00675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PEFT Env",
   "language": "python",
   "name": "peft-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
